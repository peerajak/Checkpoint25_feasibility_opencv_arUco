{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b492571d-7f1e-4fcb-b1bd-0d24f4b517e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peerajak/venv/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/peerajak/venv/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/peerajak/venv/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/peerajak/venv/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Python 2/3 compatibility\n",
    "import cv2 # Import the OpenCV library\n",
    "import numpy as np # Import Numpy library\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math # Math library\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb73450-50d2-4f0c-be5c-685348e9883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that was used to generate the ArUco marker\n",
    "aruco_dictionary_name = \"DICT_6X6_250\"\n",
    " \n",
    "# The different ArUco dictionaries built into the OpenCV library. \n",
    "ARUCO_DICT = {\n",
    "  \"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "  \"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "  \"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "  \"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "  \"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "  \"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "  \"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "  \"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "  \"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "  \"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "  \"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "  \"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "  \"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "  \"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "  \"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "  \"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "  \"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645602cf-bb56-473f-bb8f-4efe502bd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side length of the ArUco marker in meters \n",
    "aruco_marker_side_length = 0.026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acc26c7-f12f-448f-b5c4-5d8735b11f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_from_quaternion(x, y, z, w):\n",
    "  \"\"\"\n",
    "  Convert a quaternion into euler angles (roll, pitch, yaw)\n",
    "  roll is rotation around x in radians (counterclockwise)\n",
    "  pitch is rotation around y in radians (counterclockwise)\n",
    "  yaw is rotation around z in radians (counterclockwise)\n",
    "  \"\"\"\n",
    "  t0 = +2.0 * (w * x + y * z)\n",
    "  t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "  roll_x = math.atan2(t0, t1)\n",
    "      \n",
    "  t2 = +2.0 * (w * y - z * x)\n",
    "  t2 = +1.0 if t2 > +1.0 else t2\n",
    "  t2 = -1.0 if t2 < -1.0 else t2\n",
    "  pitch_y = math.asin(t2)\n",
    "      \n",
    "  t3 = +2.0 * (w * z + x * y)\n",
    "  t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "  yaw_z = math.atan2(t3, t4)\n",
    "      \n",
    "  return roll_x, pitch_y, yaw_z # in radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803c8fcc-30ff-458c-adec-5fb69267eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_coordinate_to_pixel_position(focal_x,focal_y,pixel_position_principal_point_x, pixel_position_principal_point_y, P_camra_coordinate):\n",
    "    ox = round(pixel_position_principal_point_x)\n",
    "    oy = round(pixel_position_principal_point_y)\n",
    "    xc = P_camra_coordinate[0]\n",
    "    yc = P_camra_coordinate[1]\n",
    "    zc = P_camra_coordinate[2] \n",
    "    sx = 1\n",
    "    sy = 1\n",
    "    x_im = -(focal_x*xc)/(sx*zc) + ox\n",
    "    y_im = -(focal_y*yc)/(sy*zc) + oy\n",
    "    return x_im, y_im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d38bba-38e1-481d-b59d-96509efd126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  global p98\n",
    "  global p98_r\n",
    "  global p40\n",
    "  global p40_r\n",
    "    \n",
    "  is_p98_defined = False\n",
    "  is_p40_defined = False\n",
    "  \"\"\"\n",
    "  Main method of the program.\n",
    "  \"\"\"\n",
    "  # Check that we have a valid ArUco marker\n",
    "  if ARUCO_DICT.get(aruco_dictionary_name, None) is None:\n",
    "    print(\"[INFO] ArUCo tag of '{}' is not supported\".format(\n",
    "      args[\"type\"]))\n",
    "    sys.exit(0)\n",
    " \n",
    "  # Load the camera parameters from the saved file\n",
    "  #cv_file = cv2.FileStorage( camera_calibration_parameters_filename, cv2.FILE_STORAGE_READ) \n",
    "  #mtx = cv_file.getNode('K').mat()\n",
    "  #dst = cv_file.getNode('D').mat()\n",
    "  #cv_file.release()\n",
    "\n",
    "  mtx_np = np.array([ [759.895784, 0.000000, 312.753105],[0.000000, 762.113647, 214.923553], [0., 0., 1.]], np.float32)\n",
    "  mtx = mtx_np\n",
    "  dst_np = np.array([0.062948, -0.273568, 0.005933, -0.001056, 0.000000], np.float32)   \n",
    "  prj_np = np.array([[761.265137, 0.000000, 311.720175, 0.000000],\\\n",
    "                    [0.000000, 764.304443, 215.883204, 0.000000],\\\n",
    "                    [0.000000, 0.000000, 1.000000, 0.000000]], np.float32)   \n",
    "  dst = dst_np\n",
    "  # Load the ArUco dictionary\n",
    "  print(\"[INFO] detecting '{}' markers...\".format(\n",
    "    aruco_dictionary_name))\n",
    "  this_aruco_dictionary = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_dictionary_name])\n",
    "  this_aruco_parameters = cv2.aruco.DetectorParameters_create()\n",
    "   \n",
    "  # Start the video stream\n",
    "  cap = cv2.VideoCapture(0)\n",
    "\n",
    "  if cap is None:\n",
    "        print(\"failed to capture videos\")\n",
    "        return\n",
    "\n",
    "   \n",
    "  while(True):\n",
    "      # Capture frame-by-frame\n",
    "      # This method returns True/False as well\n",
    "      # as the video frame.\n",
    "      ret, streamImage = cap.read() \n",
    "      detectingImage = streamImage.copy() \n",
    "\n",
    "      # Detect ArUco markers in the video frame\n",
    "      (corners, marker_ids, rejected) = cv2.aruco.detectMarkers(\n",
    "          detectingImage , this_aruco_dictionary, parameters=this_aruco_parameters,\n",
    "          cameraMatrix=mtx, distCoeff=dst)\n",
    "\n",
    "\n",
    "\n",
    "      # Check that at least one ArUco marker was detected\n",
    "      if marker_ids is not None: \n",
    "          # print('corners ',corners)\n",
    "          # print('marker_ids', marker_ids)\n",
    "          # Draw a square around detected markers in the video frame\n",
    "          cv2.aruco.drawDetectedMarkers(detectingImage , corners, marker_ids)\n",
    "\n",
    "          # Get the rotation and translation vectors\n",
    "          rvecs, tvecs, obj_points = cv2.aruco.estimatePoseSingleMarkers(\n",
    "            corners,\n",
    "            aruco_marker_side_length,\n",
    "            mtx,\n",
    "            dst)\n",
    "          # Print the pose for the ArUco marker\n",
    "          # The pose of the marker is with respect to the camera lens frame.\n",
    "          # Imagine you are looking through the camera viewfinder, \n",
    "          # the camera lens frame's:\n",
    "          # x-axis points to the right\n",
    "          # y-axis points straight down towards your toes\n",
    "          # z-axis points straight ahead away from your eye, out of the camera\n",
    "          for i, marker_id in enumerate(marker_ids):\n",
    "\n",
    "            # Store the translation (i.e. position) information\n",
    "            transform_translation_x = tvecs[i][0][0]\n",
    "            transform_translation_y = tvecs[i][0][1]\n",
    "            transform_translation_z = tvecs[i][0][2]\n",
    "\n",
    "            # Store the rotation information\n",
    "            rotation_matrix = np.eye(4)\n",
    "            rotation_matrix[0:3, 0:3] = cv2.Rodrigues(np.array(rvecs[i][0]))[0]\n",
    "            r = R.from_matrix(rotation_matrix[0:3, 0:3])\n",
    "            quat = r.as_quat()   \n",
    "\n",
    "            # Quaternion format     \n",
    "            transform_rotation_x = quat[0] \n",
    "            transform_rotation_y = quat[1] \n",
    "            transform_rotation_z = quat[2] \n",
    "            transform_rotation_w = quat[3] \n",
    "\n",
    "            # Euler angle format in radians\n",
    "            roll_x, pitch_y, yaw_z = euler_from_quaternion(transform_rotation_x, \n",
    "                                                           transform_rotation_y, \n",
    "                                                           transform_rotation_z, \n",
    "                                                           transform_rotation_w)\n",
    "\n",
    "            # roll_x = math.degrees(roll_x)\n",
    "            # pitch_y = math.degrees(pitch_y)\n",
    "            # yaw_z = math.degrees(yaw_z)\n",
    "            # print(\"transform_translation_x: {}\".format(transform_translation_x))\n",
    "            # print(\"transform_translation_y: {}\".format(transform_translation_y))\n",
    "            # print(\"transform_translation_z: {}\".format(transform_translation_z))\n",
    "            # print(\"roll_x: {}\".format(roll_x))\n",
    "            # print(\"pitch_y: {}\".format(pitch_y))\n",
    "            # print(\"yaw_z: {}\".format(yaw_z))\n",
    "            # print()\n",
    "            (topLeft, topRight, bottomRight, bottomLeft) = corners[i].reshape((4, 2))\n",
    "            # convert each of the (x, y)-coordinate pairs to integers\n",
    "            topRight = (int(topRight[0]), int(topRight[1]))\n",
    "            bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
    "            bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
    "            topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
    "            cX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
    "            cY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
    "            #print(\"id {} \".format(marker_id))\n",
    "            #print(\"at image position \",[cX,cY])\n",
    "            #print(\"rotation matrix\",rotation_matrix[0:3, 0:3] )\n",
    "            #print(\"translation matrix\",[transform_translation_x ,transform_translation_y,transform_translation_z])\n",
    "            #print(obj_points[i])\n",
    "            if marker_id == 98:\n",
    "                p98_im = np.array([cX,cY], dtype='>i4')\n",
    "                p98 = tvecs[i][0][0:3]\n",
    "                p98_r = rotation_matrix[0:3, 0:3]\n",
    "                #print('set 98',p98, obj_points[i])\n",
    "                is_p98_defined = True\n",
    "            if marker_id == 40:\n",
    "                p40_im = np.array([cX,cY], dtype='>i4')\n",
    "                p40 = tvecs[i][0][0:3]\n",
    "                p40_r = rotation_matrix[0:3, 0:3]  \n",
    "                #print('set 40',p40, obj_points[i])\n",
    "                is_p40_defined = True\n",
    "            #print(\"============\")\n",
    "            if is_p98_defined and is_p40_defined:\n",
    "                T_c_p98 = p98_r\n",
    "                T_c_p40 = p40_r\n",
    "\n",
    "                p40__p98 = np.dot(T_c_p98, p40 - p98  )\n",
    "                #print(p40__p98)\n",
    "\n",
    "                p98__p40 = np.dot(T_c_p40, p98 - p40  )\n",
    "                #print(p98__p40)\n",
    "                p40__p98_str = '40 in 98 frame: x={:3.2f}, y={:3.2f}, z={:3.2f} cm'.format(p40__p98[0]*100,p40__p98[1]*100,p40__p98[2]*100 )\n",
    "                p98__p40_str = '98 in 40 frame: x={:3.2f}, y={:3.2f}, z={:3.2f} cm'.format(p98__p40[0]*100,p98__p40[1]*100,p98__p40[2]*100 )\n",
    "                # Window name in which image is displayed\n",
    "                window_name = 'Image'\n",
    "                \n",
    "\n",
    "                start_point = (p98_im[0], p98_im[1])\n",
    "                end_point = (p40_im[0], p40_im[1])\n",
    "                # Black color in BGR\n",
    "                color = (0, 255, 255)\n",
    "                # Line thickness of 5 px\n",
    "                thickness = 1\n",
    "                # Using cv2.line() method\n",
    "                # Draw a diagonal black line with thickness of 5 px\n",
    "                detectingImage = cv2.line(detectingImage, start_point, end_point, color, thickness)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                focal_x = mtx_np[0][0]\n",
    "                focal_y = mtx_np[1][1]\n",
    "                pixel_position_principal_point_x = mtx_np[0][2]\n",
    "                pixel_position_principal_point_y = mtx_np[1][2]\n",
    "                #x_40_im_f, y_40_im_f = camera_coordinate_to_pixel_position(focal_x,focal_y,pixel_position_principal_point_x, pixel_position_principal_point_y, p40)\n",
    "                #x_40_im = int(round(x_40_im_f))\n",
    "                #y_40_im = int(round(y_40_im_f))\n",
    "                p40_homo = np.append(p40, 1.)\n",
    "                p40_c = np.dot(prj_np, p40_homo)\n",
    "                uv1_40 = (np.dot(mtx_np, p40_c)).flatten()\n",
    "                x_40_im = int(round(uv1_40[0]))\n",
    "                y_40_im = int(round(uv1_40[1]))                \n",
    "                #print(x_40_im,y_40_im,p40_im, p40)\n",
    "                detectingImage = cv2.circle(detectingImage, (x_40_im, y_40_im), radius=5, color=(0, 0, 255), thickness=5)\n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "                # font\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (50, 50)\n",
    "                fontScale = 0.5   \n",
    "                color = (0, 255, 255)\n",
    "                thickness = 1    \n",
    "                detectingImage = cv2.putText(detectingImage, p98__p40_str , (50, 50), font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "                detectingImage = cv2.putText(detectingImage, p40__p98_str , (50, 80), font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            # Draw the axes on the marker\n",
    "            cv2.aruco.drawAxis(detectingImage , mtx, dst, rvecs[i], tvecs[i], 0.05)\n",
    "\n",
    "      # Display the resulting frame\n",
    "\n",
    "      cv2.imshow('frame',detectingImage )\n",
    "          \n",
    "      # If \"q\" is pressed on the keyboard, \n",
    "      # exit this loop\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          # filename_org = 'data/original_image.jpg'\n",
    "          # filename_detected = 'data/detected_image.jpg'\n",
    "          # cv2.imwrite(filename_org, streamImage)\n",
    "          # cv2.imwrite(filename_detected, detectingImage)\n",
    "          break\n",
    "\n",
    "\n",
    "  \n",
    "  # Close down the video stream\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0865950-1135-404c-acd4-4f22ba91d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "[INFO] detecting 'DICT_6X6_250' markers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /home/peerajak/__Features__/opencv-4.5.2/modules/videoio/src/cap_gstreamer.cpp (1081) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "if __name__ == '__main__':\n",
    "  print(__doc__)\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07dfe974-1564-4058-bb64-bd5fc9981609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04325461 -0.04274871 -0.00035997]\n",
      "[0.04386097 0.04203054 0.00286218]\n"
     ]
    }
   ],
   "source": [
    "# This might be wrong or right. I was expecting z component of p40__p98 to be nearly zero\n",
    "# but this is because the camera calibration was done on the laptop computer\n",
    "\n",
    "T_c_p98 = p98_r\n",
    "T_c_p40 = p40_r\n",
    "\n",
    "p40__p98 = np.dot(T_c_p98, p40 - p98  )\n",
    "print(p40__p98)\n",
    "\n",
    "p98__p40 = np.dot(T_c_p40, p98 - p40  )\n",
    "print(p98__p40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e0963-d369-4c53-a084-c22df76e50d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
